{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Simple Disaggregation using NILMTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use NILMTK to train and test two of its build-in benchmarking algorithms on SynD. The source code of this tutorial is based on material that was released by the creators of NILMTK. Thanks for sharing!\n",
    "\n",
    "Remarks to this tutorial:\n",
    "\n",
    "1. We use a rather old version of NILMTK in this tutorial i.e. nilmtk <= 0.3.0\n",
    "2. With FHMM and CO, we selected rather old-fashioned than state-of-the-art disaggregators. However, we aim to provide a simple introduction to NILM in this tutorial and not a presentation of novel cutting-edge tech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Do imports!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from six import iteritems\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.disaggregate import CombinatorialOptimisation, FHMM, MLE\n",
    "\n",
    "from nilmtk.elecmeter import ElecMeterID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Let's define performance metrics and the prediction procedure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_RMSE(gt, pred):\n",
    "    rms_error = {}\n",
    "    for appliance in gt.columns:\n",
    "        rms_error[appliance] = np.sqrt(mean_squared_error(gt[appliance], pred[appliance]))\n",
    "    return pd.Series(rms_error)\n",
    "\n",
    "\n",
    "def compute_MNE(gt, pred):\n",
    "    mne = {}\n",
    "    for appliance in gt.columns:\n",
    "        mne[appliance] = np.sum(abs(gt[appliance] - pred[appliance])**2) / np.sum(gt[appliance]**2)\n",
    "    return pd.Series(mne)\n",
    "\n",
    "\n",
    "def predict(clf, test_elec, sample_period, timezone):\n",
    "    pred = {}\n",
    "    gt = {}\n",
    "\n",
    "    for i, chunk in enumerate(test_elec.mains().load(sample_period=sample_period)):\n",
    "        chunk_drop_na = chunk.dropna()\n",
    "        try:\n",
    "            pred[i] = clf.disaggregate_chunk(chunk_drop_na)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        gt[i] = {}\n",
    "\n",
    "        for meter in test_elec.submeters().meters:\n",
    "            # Only use the meters that we trained on (this saves time!)\n",
    "            gt[i][meter] = next(meter.load(sample_period=sample_period))\n",
    "        gt[i] = pd.DataFrame({k: v.squeeze() for k, v in iteritems(gt[i]) if len(v)},\n",
    "                             index=next(iter(gt[i].values())).index).dropna()\n",
    "\n",
    "    # If everything can fit in memory\n",
    "    gt_overall = pd.concat(gt)\n",
    "    gt_overall.index = gt_overall.index.droplevel()\n",
    "    pred_overall = pd.concat(pred)\n",
    "    pred_overall.index = pred_overall.index.droplevel()\n",
    "\n",
    "    # Having the same order of columns\n",
    "    gt_overall = gt_overall[pred_overall.columns]\n",
    "\n",
    "    # Intersection of index\n",
    "    gt_index_utc = gt_overall.index.tz_convert(\"UTC\")\n",
    "    pred_index_utc = pred_overall.index.tz_convert(\"UTC\")\n",
    "    common_index_utc = gt_index_utc.intersection(pred_index_utc)\n",
    "\n",
    "    common_index_local = common_index_utc.tz_convert(timezone)\n",
    "    gt_overall = gt_overall.ix[common_index_local]\n",
    "    pred_overall = pred_overall.ix[common_index_local]\n",
    "    appliance_labels = [m for m in gt_overall.columns.values]\n",
    "    gt_overall.columns = appliance_labels\n",
    "    pred_overall.columns = appliance_labels\n",
    "    return gt_overall, pred_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Define settings and create variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 ElecMeter(instance=22, building=1, dataset='SynD', appliances=[Appliance(type='kettle', instance=1)])1)]))]))]))])"
     ]
    }
   ],
   "source": [
    "################## SETTINGS ##################\n",
    "\n",
    "sample_period = 10\n",
    "\n",
    "d_dir = '/Users/christoph/datasets/SynD-release/'\n",
    "\n",
    "################## VARS ##################\n",
    "\n",
    "train = DataSet(d_dir+'SynD.h5')\n",
    "test = DataSet(d_dir+'SynD.h5')\n",
    "\n",
    "train.set_window(end=\"2020-02-07\")\n",
    "test.set_window(start=\"2020-02-07\")\n",
    "\n",
    "train_elec = train.buildings[1].elec\n",
    "test_elec = test.buildings[1].elec\n",
    "\n",
    "top_5_train_elec = train_elec.submeters().select_top_k(k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train and predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "CO\n",
      "********************\n",
      "Training model for submeter 'ElecMeter(instance=2, building=1, dataset='SynD', appliances=[Appliance(type='fridge', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=4, building=1, dataset='SynD', appliances=[Appliance(type='electric space heater', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=3, building=1, dataset='SynD', appliances=[Appliance(type='dish washer', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=9, building=1, dataset='SynD', appliances=[Appliance(type='clothes iron', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=5, building=1, dataset='SynD', appliances=[Appliance(type='washing machine', instance=1)])'\n",
      "Done training!\n",
      "Estimating power demand for 'ElecMeter(instance=2, building=1, dataset='SynD', appliances=[Appliance(type='fridge', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=4, building=1, dataset='SynD', appliances=[Appliance(type='electric space heater', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=3, building=1, dataset='SynD', appliances=[Appliance(type='dish washer', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=9, building=1, dataset='SynD', appliances=[Appliance(type='clothes iron', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=5, building=1, dataset='SynD', appliances=[Appliance(type='washing machine', instance=1)])'\n",
      "********************\n",
      "FHMM\n",
      "********************\n",
      "Training model for submeter 'ElecMeter(instance=2, building=1, dataset='SynD', appliances=[Appliance(type='fridge', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=4, building=1, dataset='SynD', appliances=[Appliance(type='electric space heater', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=3, building=1, dataset='SynD', appliances=[Appliance(type='dish washer', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=9, building=1, dataset='SynD', appliances=[Appliance(type='clothes iron', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=5, building=1, dataset='SynD', appliances=[Appliance(type='washing machine', instance=1)])'\n"
     ]
    }
   ],
   "source": [
    "################## DISAGGREGATE ##################\n",
    "predictions = {}\n",
    "\n",
    "classifiers = {'CO':CombinatorialOptimisation(), 'FHMM':FHMM()}\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(\"*\"*20)\n",
    "    print(clf_name)\n",
    "    print(\"*\" *20)\n",
    "    clf.train(top_5_train_elec, sample_period=sample_period)\n",
    "    gt, predictions[clf_name] = predict(clf, test_elec, sample_period, train.metadata['timezone'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally: Check performance of FHMM and CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "+++++ RESULTS +++++\n",
      "\n",
      "++ RMSE ++\n",
      "                                                       CO   FHMM\n",
      "ElecMeter(instance=2, building=1, dataset='SynD...  106.0   22.7\n",
      "ElecMeter(instance=4, building=1, dataset='SynD...  280.4  248.5\n",
      "ElecMeter(instance=3, building=1, dataset='SynD...  163.8  116.6\n",
      "ElecMeter(instance=9, building=1, dataset='SynD...  159.0  113.4\n",
      "ElecMeter(instance=5, building=1, dataset='SynD...  229.1  222.2\n",
      "\n",
      "++ MNE ++\n",
      "                                                       CO  FHMM\n",
      "ElecMeter(instance=2, building=1, dataset='SynD...  11.22  0.51\n",
      "ElecMeter(instance=4, building=1, dataset='SynD...   0.54  0.42\n",
      "ElecMeter(instance=3, building=1, dataset='SynD...   0.36  0.18\n",
      "ElecMeter(instance=9, building=1, dataset='SynD...   0.39  0.20\n",
      "ElecMeter(instance=5, building=1, dataset='SynD...   1.13  1.06\n"
     ]
    }
   ],
   "source": [
    "rmse = {}\n",
    "mne = {}\n",
    "\n",
    "for clf_name in classifiers.keys():\n",
    "    rmse[clf_name] = compute_RMSE(gt, predictions[clf_name])\n",
    "    mne[clf_name] = compute_MNE(gt, predictions[clf_name])\n",
    "\n",
    "print('\\n\\n+++++ RESULTS +++++')\n",
    "\n",
    "print('\\n++ RMSE ++')\n",
    "print(pd.DataFrame(rmse).round(1))\n",
    "res_1 = pd.DataFrame(rmse).round(1)\n",
    "print('\\n++ MNE ++')\n",
    "print(pd.DataFrame(mne).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for today. As you see, SynD can be used like any other NILMTK dataset. Please note that there have been significant updates to NILMTK with a major revision and new APIs.\n",
    "\n",
    "best,\n\n",
    "Christoph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nilmtk)",
   "language": "python",
   "name": "nilmtk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
